{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42beed4f-ad35-4c18-a72d-4eaa0d2a940e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61acd04-cbd2-4015-95c3-574af1cf46f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reading raw dataset \n",
    "\n",
    "train_dataset=pd.read_csv('../data/raw/train.csv')\n",
    "test_dataset=pd.read_csv('../data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e54b2-94e5-4a50-a371-7522ee1080f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding the proportion of missing value\n",
    "\n",
    "train_dataset.isnull().sum()*100/train_dataset.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9bc4f9-9a77-447a-bee4-f58b2a3ab4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of data preprocessing that needs to be done \n",
    "\n",
    "# Remove team?\n",
    "# Remove yr\n",
    "# Remove type as it only contain 1 value\n",
    "# Remove num ( not important, and will introduce overfitting )\n",
    "# Remove ftr ( need definition ) USE IN THIS EXPEREMINTAE\n",
    "# Remove pfr ( need definition ) USE IN THIS EXPEREMINTAE\n",
    "# Remove year ( based on EDA, and business asumption )\n",
    "# Remove player ID (will cause overfit)\n",
    "# Remove ht ( unusable if not processed, will consider in subsequent experiment )\n",
    "# I dont quite understand how the drafting works, but seems like only players who have values in 'pick' variable deleting this for experiment A while finding out how it works\n",
    "\n",
    "# Fill in missing value in ht with average ht ( Remove for experiment A )\n",
    "# Data engineer Rec_Rank \n",
    "# Fill in missing value in ast_tov with mean \n",
    "# Engineer dunks_ratio by dunksmade/dunksmiss_dunksmade\n",
    "# Rec_Rank = need to fill out missing value with 0 to capture the state of unranked\n",
    "\n",
    "# Remove missing obs from rimmade\n",
    "# Remove missing obs from drtg\n",
    "# Remove missing obs from mp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dee353-a561-44b0-a7fa-571795f98a19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git add .\n",
    "# !git commit -m \"Initial EDA\"\n",
    "# !git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd90fd-060a-44b9-97ed-d7dd43f07100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copying training and testing dataset\n",
    "\n",
    "\n",
    "train_dataset_copy=train_dataset.copy()\n",
    "test_dataset_copy=test_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348514b1-b14c-42c7-a02b-ec617a64fe9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping columns that we deem uneccesary from training and test\n",
    "\n",
    "columns_to_drop=['team','yr','num','year','player_id','ht','pick','type']\n",
    "\n",
    "train_dataset_copy.drop(columns=columns_to_drop,inplace=True)\n",
    "test_dataset_copy.drop(columns=columns_to_drop,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8edc7-1245-46a7-b5a4-e7e3c241d064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removing observations with missing values in listed columns\n",
    "\n",
    "train_dataset_copy.dropna(subset=['rimmade','drtg','mp'],inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423b493-f54f-481a-9190-692f9cdc9e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filling in the missing value in ast_tov with the average ast_tov\n",
    "\n",
    "# Converting the format of height from string to number\n",
    "\n",
    "avg_height_train=train_dataset_copy['ast_tov'].mean()\n",
    "\n",
    "train_dataset_copy['ast_tov'].fillna(avg_height_train,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60beb3eb-de7f-49ba-b46b-2e43c2ed393d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replacing dunks_ratio missing value with 0\n",
    "\n",
    "# Missing value on dunks_ratio are caused by no succesful dunks were made\n",
    "\n",
    "train_dataset_copy['dunks_ratio'].fillna(0,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fac84-7d44-42f1-ae5d-2e760bea0a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Replacing rim_ratio missing value with 0\n",
    "\n",
    "# Missing value on rim_ratio are caused by no succesful rimmshot were made\n",
    "\n",
    "\n",
    "train_dataset_copy['rim_ratio'].fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48baa9b4-f061-4175-b108-cc65e13a8b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Replacing mid_ratio missing value with 0\n",
    "\n",
    "# Missing value on mid_ratio are caused by no midmade_midmiss were made\n",
    "\n",
    "\n",
    "train_dataset_copy['mid_ratio'].fillna(0,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e78d7b-f2c6-47e1-8b5b-161a28bfab65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replacing Rec_Rank missing value with 0\n",
    "\n",
    "# Need to fill out missing value in Rec_Rank with 0 to capture the state of unranked\n",
    "\n",
    "\n",
    "train_dataset_copy['Rec_Rank'].fillna(0,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5850fa7c-c33d-40a2-998b-3e87503757cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the test dataset seperately as it needs different treatment compared to \n",
    "\n",
    "\n",
    "# Filling in the missing value in this list  with the average ast_tov\n",
    "\n",
    "columns_fill_with_avg=['drtg','adrtg','dporpag','stops',\n",
    "                       'bpm','obpm','dbpm','gbpm','ogbpm',\n",
    "                       'dgbpm','ast_tov']\n",
    "                    \n",
    "for column in columns_fill_with_avg:\n",
    "    average=test_dataset_copy[column].mean()\n",
    "    test_dataset_copy[column].fillna(average,inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "# Filling in the missing value in this list  with 0\n",
    "\n",
    "columns_fill_with_0=['rimmade','rimmade_rimmiss','midmade',\n",
    "                     'midmade_midmiss','dunksmade','dunksmiss_dunksmade',\n",
    "                     'rim_ratio','dunks_ratio','mid_ratio','Rec_Rank']\n",
    "\n",
    "for column in columns_fill_with_0:\n",
    "    value_fillup=0\n",
    "    test_dataset_copy[column].fillna(value_fillup,inplace=True)\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a35cd-ed22-4924-b65f-df421d36ad12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cleaned=train_dataset_copy\n",
    "test_cleaned=test_dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f23e57-e1f9-4e48-ba22-d07187055cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d7cf0-f93b-4494-9e7c-36f28ca6d393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Taking out the target variable\n",
    "target = train_cleaned.pop('drafted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d5709-ca29-4248-bd1e-98ebcea46244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing one hot encoder and standard scaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da232164-143f-4202-93c0-f0af9131d2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7a270-55fa-4f01-adea-11dd1ff11209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transforming cat variables with one hot encoding \n",
    "cat_variables=['conf']\n",
    "\n",
    "categorical_features_train_ohe=ohe.fit_transform(train_cleaned[cat_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463070f-8db2-44c7-87dc-d34fce5f3963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turning OHE into dataframe\n",
    "\n",
    "features_train=pd.DataFrame(categorical_features_train_ohe, columns=ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fceef8c-78ba-4305-95bf-8c81e9c055e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate scaler\n",
    "\n",
    "scaler= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d566e-df9e-4582-bdbe-54aa5f7b3668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scaling numerical variables\n",
    "\n",
    "# Listing all numerical columns\n",
    "num_columns_train=list(train_cleaned.select_dtypes('number').columns)\n",
    "\n",
    "# Fit and transform to scale then add them to features dataframe\n",
    "\n",
    "features_train[num_columns_train]=scaler.fit_transform(train_cleaned[num_columns_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f392968-8447-4d3b-85ae-21e3c8e3655a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Importing resample to undersample\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c50f7-a16a-4535-82b4-91871f37ffd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Combine target and features to split them altogether\n",
    "\n",
    "features_train.reset_index(drop=True, inplace=True)\n",
    "target_df_train = pd.DataFrame({'drafted':target})\n",
    "target_df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "processed_df_train = pd.concat([features_train, target_df_train], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cdc06-d7c3-41ae-8f17-3ba68b10c287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_df_train.to_csv('../data/processed/experiment_c_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6545128-e6fd-41a2-b692-1f1a4b098f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Undersampling \n",
    "\n",
    "majority_train= processed_df_train[processed_df_train['drafted']==0]\n",
    "majority_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "minority_train= processed_df_train[processed_df_train['drafted']==1]\n",
    "minority_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Undersample majority class\n",
    "undersampled_majority = resample(\n",
    "    majority_train,\n",
    "    replace=False,  # Without replacement to decrease instances\n",
    "    n_samples=(round((len(minority_train)/0.3)-len(minority_train))),  # I want the split to be 70:30 to also capture the scarcity of the drafted\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "undersampled_majority.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c034c15-b425-4fe6-879e-119453a184fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combining the majority and minority back\n",
    "\n",
    "\n",
    "fully_processed_dataset_train = pd.concat([undersampled_majority, minority_train], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ae1ab-63f9-40da-aec5-3b33448475d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_train_undersampled=fully_processed_dataset_train.pop('drafted')\n",
    "features_train_undersampled=fully_processed_dataset_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832daf1e-f3dc-4c65-bdc6-7bd8c25019be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_train_undersampled.to_csv('../data/processed/x_undersampled_train_experiment_C.csv', index=False)\n",
    "target_train_undersampled.to_csv('../data/processed/y_undersampled_train_experiment_C.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934df94a-04a3-4335-9bb2-be5667442317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_train_undersampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80719aa3-2cc0-4b68-8297-f08b31738e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Using custom function \n",
    "\n",
    "\n",
    "# Changing working direction so I can call the customized function\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/danielalexander/Desktop/Advanced_ML_Algo/adv_ML_application_assignment_1/')\n",
    "\n",
    "\n",
    "# from src.models import split_sets_random \n",
    "\n",
    "from src.models import split_sets_random\n",
    "\n",
    "\n",
    "x_train, x_val, y_train, y_val = split_sets_random.split_sets_random(features_train_undersampled,target_train_undersampled)\n",
    "\n",
    "# Changing working direction back to original\n",
    "os.chdir('/Users/danielalexander/Desktop/Advanced_ML_Algo/adv_ML_application_assignment_1/notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605e659-975d-41d1-ba10-416e3f30db3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': range(50,500),        # Number of weak learners\n",
    "    'learning_rate': [0.001,0.01, 0.1, 1.0,2,5],     # Learning rate\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=10),  \n",
    "                       DecisionTreeClassifier(max_depth=5),\n",
    "                       DecisionTreeClassifier(max_depth=7),\n",
    "                       DecisionTreeClassifier(max_depth=500),\n",
    "                       DecisionTreeClassifier(max_depth=1000)],                   \n",
    "    'algorithm': ['SAMME', 'SAMME.R'],     # Algorithm options\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ada_boost_d = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=ada_boost_d,n_iter=50,\n",
    "                                 param_distributions=param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# # Fit the GridSearchCV object to the training data\n",
    "# random_search.fit(features_train_undersampled, array)\n",
    "\n",
    "# # Print the best parameters found\n",
    "# print(\"Best parameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d7a29-75e8-4bed-81ac-710c7aaee350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inititating adaptive booster model\n",
    "\n",
    "ada_boost_classifier_c= AdaBoostClassifier(random_state=42,\n",
    "                                          n_estimators= 468,\n",
    "                                          learning_rate=1,\n",
    "                                          base_estimator=DecisionTreeClassifier (max_depth=7),\n",
    "                                          algorithm='SAMME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2359e450-f438-40af-a656-a632d9e2516a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fitting and getting the recall score for train data\n",
    "\n",
    "from sklearn.metrics import recall_score, classification_report , accuracy_score\n",
    "\n",
    "ada_boost_classifier_c.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909f5ae-aaa0-4e42-a901-f5131811b3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# getting the recall score for train data\n",
    "from sklearn.metrics import recall_score, classification_report , accuracy_score\n",
    "\n",
    "predictions_train = ada_boost_classifier_c.predict(x_train)\n",
    "\n",
    "report_train= classification_report(y_train, predictions_train)\n",
    "print(report_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9082180-37e1-4441-9a2f-b1d52d62c4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump (ada_boost_classifier_c,'../models/adaboost_experiment_c.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d9481-aa43-481f-a302-b62a754d68ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Confusion matrix for full data without undersampling\n",
    "ConfusionMatrixDisplay.from_estimator(ada_boost_classifier_c, x_train, y_train, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e87b51-77f2-4399-abc5-88901a197814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# getting the recall score for train data\n",
    "from sklearn.metrics import recall_score, classification_report , accuracy_score\n",
    "\n",
    "predictions_val = ada_boost_classifier_c.predict(x_val)\n",
    "\n",
    "report_train= classification_report(y_val, predictions_val)\n",
    "print(report_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81c652-1b8d-4128-b7ef-8fff3750ebb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Confusion matrix for full data without undersampling\n",
    "ConfusionMatrixDisplay.from_estimator(ada_boost_classifier_c, x_val, y_val, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e94c99-b756-4fd3-bb32-557c4d5a08c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the ROC score for train\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "proba_predictions = ada_boost_classifier_c.predict_proba(x_train)\n",
    "\n",
    "roc_auc = roc_auc_score(y_train, proba_predictions[:, 1])\n",
    "\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b0273-048d-48d3-b0fc-fa4ca7d2aaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "proba_predictions = ada_boost_classifier_c.predict_proba(x_val)\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, proba_predictions[:, 1])\n",
    "\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989cbd40-6f75-4829-9463-bf9af74c2923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preparing the features on test data\n",
    "\n",
    "\n",
    "cat_features_test=test_cleaned.pop('conf')\n",
    "num_features_test=test_cleaned\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a4ec4-6fc0-473e-b7ee-15d5121c4d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying one hot encoding to test data\n",
    "\n",
    "\n",
    "test_ohe= OneHotEncoder(sparse_output=False)\n",
    "\n",
    "ohe_array_test=test_ohe.fit_transform(pd.DataFrame(cat_features_test,columns=['conf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af752008-1ce4-4e47-b854-4638969eba1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Applying scaling to test data\n",
    "\n",
    "\n",
    "test_scale= StandardScaler()\n",
    "\n",
    "scale_array_test= test_scale.fit_transform(num_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ec83e-52b1-4274-b50a-7c39f9200cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turning OHE in test into dataframe\n",
    "\n",
    "x_test_processed=pd.DataFrame(ohe_array_test, columns=test_ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d9e24-59f3-4ae8-96db-aa73e102ecf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding scaled features in test into dataframe\n",
    "\n",
    "num_columns_test=list(num_features_test.select_dtypes('number').columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_test_processed[num_columns_test]=scale_array_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf3472-9bc1-464d-8e0c-4aea801c3627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_train = features_train.columns.tolist()\n",
    "columns_x_test_processed = x_test_processed.columns.tolist()\n",
    "\n",
    "\n",
    "# Columns present in train but not in test\n",
    "columns_only_in_train = [col for col in columns_train if col not in columns_x_test_processed]\n",
    "\n",
    "\n",
    "columns_only_in_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075854cc-05bb-4208-9d56-56d41d6a0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting additional columns to test dataframe so it matches the train data\n",
    "\n",
    "x_test_processed[columns_only_in_train]=0\n",
    "\n",
    "# Reindex DataFrame test to match the column order of DataFrame train\n",
    "x_test_processed = x_test_processed.reindex(columns=features_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6b207-b0f8-446c-8c94-66bbb92d9b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_processed.to_csv('../data/processed/experiment_C_test_x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf3c8a-8cab-46fc-a841-a7ea3db1b3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prediction_test= ada_boost_classifier_c.predict(x_test_processed)\n",
    "\n",
    "proba_predictions_test = ada_boost_classifier_c.predict_proba(x_test_processed)\n",
    "\n",
    "\n",
    "player_id=test_dataset['player_id']\n",
    "\n",
    "# Converting series to dataframe\n",
    "test_prediction = pd.DataFrame({'player_id': player_id})\n",
    "\n",
    "# Adding the probability\n",
    "test_prediction['drafted']=proba_predictions_test[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00a022-02a5-43b6-a3f5-acdb7b985892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git add .\n",
    "# !git commit -m \"Finishing up experiment C, adaptivebooster\"\n",
    "# !git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f8d32-f49b-4b04-9b01-2b4681b6141d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_processed.to_csv('../data/processed/experiment_C_test_x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ba3d1-bc67-42dc-96e4-52dd26b2c2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prediction.to_csv('../data/processed/experiment_C_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0a7de-0be7-4068-9437-977708d5bf54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git add .\n",
    "# !git commit -m \"Dumping models to the model folder\"\n",
    "# !git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
